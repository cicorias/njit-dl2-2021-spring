{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5. Convolutions for Images.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"ze6ZgZrtim8f"},"source":["!pip install d2l==0.16.1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"origin_pos":2,"tab":["pytorch"],"id":"WYVbR_R2iZnN","executionInfo":{"status":"ok","timestamp":1612486831593,"user_tz":300,"elapsed":3355,"user":{"displayName":"Ioannis Koutis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64","userId":"17239720917701380808"}}},"source":["from d2l import torch as d2l\n","import torch\n","from torch import nn"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"origin_pos":3,"tab":["pytorch"],"id":"tWTQOPliiZnO","executionInfo":{"status":"ok","timestamp":1612486949628,"user_tz":300,"elapsed":525,"user":{"displayName":"Ioannis Koutis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64","userId":"17239720917701380808"}}},"source":["def corr2d(X, K):  #@save\n","    \"\"\"Compute 2D cross-correlation.\"\"\"\n","    h, w = K.shape\n","    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n","    for i in range(Y.shape[0]):\n","        for j in range(Y.shape[1]):\n","            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n","    return Y"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":5,"id":"PO1OgjA4iZnP"},"source":["We can construct the input tensor `X` and the kernel tensor `K`\n","from :numref:`fig_correlation`\n","to validate the output of the above implementation\n","of the two-dimensional cross-correlation operation.\n"]},{"cell_type":"code","metadata":{"origin_pos":6,"tab":["pytorch"],"colab":{"base_uri":"https://localhost:8080/"},"id":"4INUffbniZnQ","executionInfo":{"status":"ok","timestamp":1612486951824,"user_tz":300,"elapsed":443,"user":{"displayName":"Ioannis Koutis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64","userId":"17239720917701380808"}},"outputId":"bb81460f-7b85-46fb-d298-ac07db9bda76"},"source":["X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n","K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n","corr2d(X, K)"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[19., 25.],\n","        [37., 43.]])"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"origin_pos":7,"id":"R0xljoZQiZnS"},"source":["## Convolutional Layers\n","\n","A convolutional layer cross-correlates the input and kernel\n","and adds a scalar bias to produce an output.\n","The two parameters of a convolutional layer\n","are the kernel and the scalar bias.\n","When training models based on convolutional layers,\n","we typically initialize the kernels randomly,\n","just as we would with a fully-connected layer.\n","\n","We are now ready to implement a two-dimensional convolutional layer\n","based on the `corr2d` function defined above.\n","In the `__init__` constructor function,\n","we declare `weight` and `bias` as the two model parameters.\n","The forward propagation function\n","calls the `corr2d` function and adds the bias.\n"]},{"cell_type":"code","metadata":{"origin_pos":9,"tab":["pytorch"],"id":"fRNZ-l9LiZnS","executionInfo":{"status":"ok","timestamp":1612487015710,"user_tz":300,"elapsed":443,"user":{"displayName":"Ioannis Koutis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64","userId":"17239720917701380808"}}},"source":["class Conv2D(nn.Module):\n","    def __init__(self, kernel_size):\n","        super().__init__()\n","        self.weight = nn.Parameter(torch.rand(kernel_size))\n","        self.bias = nn.Parameter(torch.zeros(1))\n","\n","    def forward(self, x):\n","        return corr2d(x, self.weight) + self.bias"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":11,"id":"HFDdhFK8iZnT"},"source":["In\n","$h \\times w$ convolution\n","or a $h \\times w$ convolution kernel,\n","the height and width of the convolution kernel are $h$ and $w$, respectively.\n","We also refer to\n","a convolutional layer with a $h \\times w$\n","convolution kernel simply as a $h \\times w$ convolutional layer. \n","\n","\n","## Object Edge Detection in Images\n","\n","Let us take a moment to parse a simple application of a convolutional layer:\n","detecting the edge of an object in an image\n","by finding the location of the pixel change.\n","First, we construct an \"image\" of $6\\times 8$ pixels.\n","The middle four columns are black (0) and the rest are white (1).\n"]},{"cell_type":"code","metadata":{"origin_pos":12,"tab":["pytorch"],"colab":{"base_uri":"https://localhost:8080/"},"id":"VfRGyYhpiZnV","executionInfo":{"status":"ok","timestamp":1612487018554,"user_tz":300,"elapsed":442,"user":{"displayName":"Ioannis Koutis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64","userId":"17239720917701380808"}},"outputId":"e64b739b-8328-418c-a097-fbc319e6d1dd"},"source":["X = torch.ones((6, 8))\n","X[:, 2:6] = 0\n","X"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n","        [1., 1., 0., 0., 0., 0., 1., 1.],\n","        [1., 1., 0., 0., 0., 0., 1., 1.],\n","        [1., 1., 0., 0., 0., 0., 1., 1.],\n","        [1., 1., 0., 0., 0., 0., 1., 1.],\n","        [1., 1., 0., 0., 0., 0., 1., 1.]])"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"origin_pos":14,"id":"EXLWJqcwiZnW"},"source":["Next, we construct a kernel `K` with a height of 1 and a width of 2.\n","When we perform the cross-correlation operation with the input,\n","if the horizontally adjacent elements are the same,\n","the output is 0. Otherwise, the output is non-zero.\n"]},{"cell_type":"code","metadata":{"origin_pos":15,"tab":["pytorch"],"id":"aJKEnnz1iZnW","executionInfo":{"status":"ok","timestamp":1612487021455,"user_tz":300,"elapsed":445,"user":{"displayName":"Ioannis Koutis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64","userId":"17239720917701380808"}}},"source":["K = torch.tensor([[1.0, -1.0]])"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":16,"id":"LJdmydlyiZnW"},"source":["We are ready to perform the cross-correlation operation\n","with arguments `X` (our input) and `K` (our kernel).\n","As you can see, we detect 1 for the edge from white to black\n","and -1 for the edge from black to white.\n","All other outputs take value 0.\n"]},{"cell_type":"code","metadata":{"origin_pos":17,"tab":["pytorch"],"colab":{"base_uri":"https://localhost:8080/"},"id":"y5_8jBh_iZnW","executionInfo":{"status":"ok","timestamp":1612487023985,"user_tz":300,"elapsed":445,"user":{"displayName":"Ioannis Koutis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64","userId":"17239720917701380808"}},"outputId":"1d98c7c4-5e77-4946-e74d-9c32dd8057db"},"source":["Y = corr2d(X, K)\n","Y"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"origin_pos":18,"id":"v5aCP-r3iZnX"},"source":["We can now apply the kernel to the transposed image.\n","As expected, it vanishes. The kernel `K` only detects vertical edges.\n"]},{"cell_type":"code","metadata":{"origin_pos":19,"tab":["pytorch"],"colab":{"base_uri":"https://localhost:8080/"},"id":"6-pXLoQbiZnX","executionInfo":{"status":"ok","timestamp":1612487030782,"user_tz":300,"elapsed":462,"user":{"displayName":"Ioannis Koutis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64","userId":"17239720917701380808"}},"outputId":"1955d093-eba0-4bbd-e5bf-13d0ab8844a8"},"source":["corr2d(X.t(), K)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.]])"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"origin_pos":20,"id":"El4yJCfjiZnX"},"source":["## Learning a Kernel\n","\n","Designing an edge detector by finite differences `[1, -1]` is neat\n","if we know this is precisely what we are looking for.\n","However, as we look at larger kernels,\n","and consider successive layers of convolutions,\n","it might be impossible to specify\n","precisely what each filter should be doing manually.\n","\n","Now let us see whether we can learn the kernel that generated `Y` from `X`\n","by looking at the input--output pairs only.\n","We first construct a convolutional layer\n","and initialize its kernel as a random tensor.\n","Next, in each iteration, we will use the squared error\n","to compare `Y` with the output of the convolutional layer.\n","We can then calculate the gradient to update the kernel.\n","For the sake of simplicity,\n","in the following\n","we use the built-in class\n","for two-dimensional convolutional layers\n","and ignore the bias.\n"]},{"cell_type":"code","metadata":{"origin_pos":22,"tab":["pytorch"],"colab":{"base_uri":"https://localhost:8080/"},"id":"D543C2bDiZnY","executionInfo":{"status":"ok","timestamp":1612467509503,"user_tz":300,"elapsed":255,"user":{"displayName":"Ioannis Koutis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64","userId":"17239720917701380808"}},"outputId":"360e0ec6-d4bb-4e3b-c0b4-d8bc60107de1"},"source":["# Construct a two-dimensional convolutional layer with 1 output channel and a\n","# kernel of shape (1, 2). For the sake of simplicity, we ignore the bias here\n","conv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False)\n","\n","# The two-dimensional convolutional layer uses four-dimensional input and\n","# output in the format of (example channel, height, width), where the batch\n","# size (number of examples in the batch) and the number of channels are both 1\n","X = X.reshape((1, 1, 6, 8))\n","Y = Y.reshape((1, 1, 6, 7))\n","\n","for i in range(10):\n","    Y_hat = conv2d(X)\n","    l = (Y_hat - Y) ** 2\n","    conv2d.zero_grad()\n","    l.sum().backward()\n","    # Update the kernel\n","    conv2d.weight.data[:] -= 3e-2 * conv2d.weight.grad\n","    if (i + 1) % 2 == 0:\n","        print(f'batch {i + 1}, loss {l.sum():.3f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["batch 2, loss 9.158\n","batch 4, loss 2.611\n","batch 6, loss 0.878\n","batch 8, loss 0.328\n","batch 10, loss 0.129\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"origin_pos":24,"id":"3z_pgx3miZnY"},"source":["Note that the error has dropped to a small value after 10 iterations. Now we will take a look at the kernel tensor we learned.\n"]},{"cell_type":"code","metadata":{"origin_pos":26,"tab":["pytorch"],"id":"H17Yq_YTiZnZ","outputId":"e42f7eeb-8f4c-491b-f918-835c66deaf8e"},"source":["conv2d.weight.data.reshape((1, 2))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.9654, -1.0102]])"]},"metadata":{"tags":[]},"execution_count":10}]}]}