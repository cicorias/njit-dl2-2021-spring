{"nbformat":4,"nbformat_minor":0,"metadata":{"language_info":{"name":"python"},"colab":{"name":"encoder-decoder.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"origin_pos":0,"id":"D6DHHVQ69BYm"},"source":["# Encoder-Decoder Architecture\n","\n","\n","into an interface that will be implemented later.\n","\n","## Encoder\n","\n","In the encoder interface,\n","we just specify that\n","the encoder takes variable-length sequences as the input `X`.\n","The implementation will be provided \n","by any model that inherits this base `Encoder` class.\n"]},{"cell_type":"code","metadata":{"origin_pos":2,"tab":["pytorch"],"id":"_AknOX379BYu"},"source":["from torch import nn\n","\n","#@save\n","class Encoder(nn.Module):\n","    \"\"\"The base encoder interface for the encoder-decoder architecture.\"\"\"\n","    def __init__(self, **kwargs):\n","        super(Encoder, self).__init__(**kwargs)\n","\n","    def forward(self, X, *args):\n","        raise NotImplementedError"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":3,"id":"8RozizYS9BYv"},"source":["## Decoder\n","\n","In the following decoder interface,\n","we add an additional `init_state` function\n","to convert the encoder output (`enc_outputs`)\n","into the encoded state.\n","Note that this step\n","may need extra inputs such as \n","the valid length of the input,\n","which was explained\n","in :numref:`subsec_mt_data_loading`.\n","To generate a variable-length sequence token by token,\n","every time the decoder\n","may map an input (e.g., the generated token at the previous time step)\n","and the encoded state\n","into an output token at the current time step.\n"]},{"cell_type":"code","metadata":{"origin_pos":5,"tab":["pytorch"],"id":"OcrzJWYN9BYw"},"source":["#@save\n","class Decoder(nn.Module):\n","    \"\"\"The base decoder interface for the encoder-decoder architecture.\"\"\"\n","    def __init__(self, **kwargs):\n","        super(Decoder, self).__init__(**kwargs)\n","\n","    def init_state(self, enc_outputs, *args):\n","        raise NotImplementedError\n","\n","    def forward(self, X, state):\n","        raise NotImplementedError"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":6,"id":"oDPdx3Sk9BYw"},"source":["## Putting the Encoder and Decoder Together\n","\n","In the end,\n","the encoder-decoder architecture\n","contains both an encoder and a decoder,\n","with optionally extra arguments.\n","In the forward propagation,\n","the output of the encoder\n","is used to produce the encoded state,\n","and this state\n","will be further used by the decoder as one of its input.\n"]},{"cell_type":"code","metadata":{"origin_pos":8,"tab":["pytorch"],"id":"UihvAus29BYw"},"source":["#@save\n","class EncoderDecoder(nn.Module):\n","    \"\"\"The base class for the encoder-decoder architecture.\"\"\"\n","    def __init__(self, encoder, decoder, **kwargs):\n","        super(EncoderDecoder, self).__init__(**kwargs)\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, enc_X, dec_X, *args):\n","        enc_outputs = self.encoder(enc_X, *args)\n","        dec_state = self.decoder.init_state(enc_outputs, *args)\n","        return self.decoder(dec_X, dec_state)"],"execution_count":null,"outputs":[]}]}