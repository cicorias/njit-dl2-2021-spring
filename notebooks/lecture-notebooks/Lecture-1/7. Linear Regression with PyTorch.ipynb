{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"7. Linear Regression with PyTorch.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN3xvHdPLuFx8pu0vqgAWFy"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QfIQS09RY19n","executionInfo":{"status":"ok","timestamp":1611278269505,"user_tz":300,"elapsed":10890,"user":{"displayName":"Ioannis Koutis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64","userId":"17239720917701380808"}},"outputId":"3be0da4c-f98b-4be4-e566-9c1a8c172c63"},"source":["import numpy as np\r\n","import sklearn\r\n","import torch\r\n","import torch.optim as optim\r\n","import torch.nn as nn\r\n","\r\n","!pip install torchviz\r\n","from torchviz import make_dot"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting torchviz\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n","\r\u001b[K     |████████                        | 10kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.3MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.7.0+cu101)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (0.8)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.19.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (0.16.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (3.7.4.3)\n","Building wheels for collected packages: torchviz\n","  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchviz: filename=torchviz-0.0.1-cp36-none-any.whl size=3522 sha256=db584ad30ea0004326f00c17494b43534996aff2f2ed44a347a370730da7bf15\n","  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n","Successfully built torchviz\n","Installing collected packages: torchviz\n","Successfully installed torchviz-0.0.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CQWEHWbWM0ZQ"},"source":["### **Create data in NumPy**\r\n","\r\n","Each point comes from the 'ideal' line $y = 2x +1$, but adding some random small number. The goal will be to find what line fits the data as well as possible. And that line should be very close to that ideal line. "]},{"cell_type":"code","metadata":{"id":"gsIRmSAnMc1u"},"source":["\r\n","\r\n","# Data Generation\r\n","np.random.seed(42)\r\n","x = np.random.rand(100, 1)\r\n","y = 1 + 2 * x + .1 * np.random.randn(100, 1)\r\n","\r\n","# Shuffles the indices\r\n","idx = np.arange(100)\r\n","np.random.shuffle(idx)\r\n","\r\n","# Uses first 80 random indices for train\r\n","train_idx = idx[:80]\r\n","# Uses the remaining indices for validation\r\n","val_idx = idx[80:]\r\n","\r\n","# Generates train and validation sets\r\n","x_train, y_train = x[train_idx], y[train_idx]\r\n","x_val, y_val = x[val_idx], y[val_idx]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uZvjx-BcRLpK"},"source":["### **Linear Regression with NumPy**\r\n","\r\n","The following code implements gradient descent. It just sets two parameters $(a, b)$ and searches for the lines $y = b\\cdot x + a$ that minimizes the mean square error. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E3mWZ7CMOIg0","executionInfo":{"status":"ok","timestamp":1611204814145,"user_tz":300,"elapsed":1457,"user":{"displayName":"Ioannis Koutis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64","userId":"17239720917701380808"}},"outputId":"fde536ac-e2fa-4855-9349-2a7be2bf7696"},"source":["np.random.seed(42)\r\n","a = np.random.randn(1)\r\n","b = np.random.randn(1)\r\n","\r\n","print(a, b)\r\n","\r\n","# Sets learning rate\r\n","lr = 1e-1\r\n","# Defines number of epochs\r\n","n_epochs = 1000\r\n","\r\n","for epoch in range(n_epochs):\r\n","    # Computes our model's predicted output\r\n","    yhat = a + b * x_train\r\n","    \r\n","    # The error  \r\n","    error = (y_train - yhat)\r\n","    # It is a regression, so it computes mean squared error (MSE)\r\n","    loss = (error ** 2).mean()\r\n","    \r\n","    # Computes gradients for both \"a\" and \"b\" parameters\r\n","    a_grad = -2 * error.mean()\r\n","    b_grad = -2 * (x_train * error).mean()\r\n","    \r\n","    # Updates parameters using gradients and the learning rate\r\n","    a = a - lr * a_grad\r\n","    b = b - lr * b_grad\r\n","    \r\n","print(a, b)\r\n","\r\n","# Sanity Check: do we get the same results as our gradient descent?\r\n","from sklearn.linear_model import LinearRegression\r\n","linr = LinearRegression()\r\n","linr.fit(x_train, y_train)\r\n","print(linr.intercept_, linr.coef_[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[0.49671415] [-0.1382643]\n","[1.02354094] [1.96896411]\n","[1.02354075] [1.96896447]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"G4-V5PS0afFH"},"source":["### **Getting things done with PyTorch**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qdrb0_-sa3is","executionInfo":{"status":"ok","timestamp":1611207096293,"user_tz":300,"elapsed":439,"user":{"displayName":"Ioannis Koutis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64","userId":"17239720917701380808"}},"outputId":"ea9367cb-7aee-450f-bd29-7839ee82592a"},"source":["# Put the data in CPU (or GPU if available)\r\n","\r\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n","\r\n","# Our data was in Numpy arrays, but we need to transform them into PyTorch's Tensors\r\n","# and then we send them to the chosen device\r\n","x_train_tensor = torch.from_numpy(x_train).float().to(device)\r\n","y_train_tensor = torch.from_numpy(y_train).float().to(device)\r\n","\r\n","# Here we can see the difference - notice that .type() is more useful\r\n","# since it also tells us WHERE the tensor is (device)\r\n","print(type(x_train), type(x_train_tensor), x_train_tensor.type())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'numpy.ndarray'> <class 'torch.Tensor'> torch.FloatTensor\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LKdpx82VSl89"},"source":["# Create the two parameters. We require gradients and put them on the device at creation time.\r\n","\r\n","torch.manual_seed(42)\r\n","a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\r\n","b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\r\n","print(a, b)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eKvl7myycxoq","executionInfo":{"status":"ok","timestamp":1611207975884,"user_tz":300,"elapsed":466,"user":{"displayName":"Ioannis Koutis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64","userId":"17239720917701380808"}},"outputId":"6ea769ac-a2ba-407a-8cb5-47e620498368"},"source":["\r\n","lr = 1e-1\r\n","n_epochs = 1000\r\n","\r\n","torch.manual_seed(42)\r\n","a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\r\n","b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\r\n","\r\n","for epoch in range(n_epochs):\r\n","    yhat = a + b * x_train_tensor   # current predictions\r\n","    error = y_train_tensor - yhat   # error\r\n","    loss = (error ** 2).mean()      # compute loss\r\n","\r\n","    # No more manual computation of gradients! \r\n","    # a_grad = -2 * error.mean()\r\n","    # b_grad = -2 * (x_tensor * error).mean()\r\n","    \r\n","    # We just tell PyTorch to work its way BACKWARDS from the specified loss!\r\n","    loss.backward()\r\n","    # Let's check the computed gradients...\r\n","    #print(a.grad)\r\n","    #print(b.grad)\r\n","    \r\n","    # What about UPDATING the parameters? Not so fast...\r\n","    \r\n","    # FIRST ATTEMPT\r\n","    # AttributeError: 'NoneType' object has no attribute 'zero_'\r\n","    # a = a - lr * a.grad\r\n","    # b = b - lr * b.grad\r\n","    # print(a)\r\n","\r\n","    # SECOND ATTEMPT\r\n","    # RuntimeError: a leaf Variable that requires grad has been used in an in-place operation.\r\n","    # a -= lr * a.grad\r\n","    # b -= lr * b.grad        \r\n","    \r\n","    # THIRD ATTEMPT\r\n","    # We need to use NO_GRAD to keep the update out of the gradient computation\r\n","    # Why is that? It boils down to the DYNAMIC GRAPH that PyTorch uses...\r\n","    with torch.no_grad():\r\n","        a -= lr * a.grad\r\n","        b -= lr * b.grad\r\n","    \r\n","    # PyTorch is \"clingy\" to its computed gradients, we need to tell it to let it go...\r\n","    a.grad.zero_()\r\n","    b.grad.zero_()\r\n","    \r\n","print(a, b)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WfKBwPKyfcmg"},"source":["### **What is the Dynamic DAG Graph?**"]},{"cell_type":"code","metadata":{"id":"vXYs4035eia4"},"source":["torch.manual_seed(42)\r\n","a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\r\n","b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\r\n","\r\n","yhat = a + b * x_train_tensor\r\n","error = y_train_tensor - yhat\r\n","loss = (error ** 2).mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":249},"id":"C-g34xn4e5yn","executionInfo":{"status":"ok","timestamp":1611208052572,"user_tz":300,"elapsed":522,"user":{"displayName":"Ioannis Koutis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64","userId":"17239720917701380808"}},"outputId":"9c3c89ef-f412-431f-9cba-f2f1113d60f3"},"source":["make_dot(yhat)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<graphviz.dot.Digraph at 0x7f10d66eae48>"],"image/svg+xml":"<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"172pt\" height=\"171pt\"\n viewBox=\"0.00 0.00 171.50 171.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 167)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-167 167.5,-167 167.5,4 -4,4\"/>\n<!-- 139710293778952 -->\n<g id=\"node1\" class=\"node\">\n<title>139710293778952</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"118,-21 26,-21 26,0 118,0 118,-21\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 139710293782144 -->\n<g id=\"node2\" class=\"node\">\n<title>139710293782144</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"54,-92 0,-92 0,-57 54,-57 54,-92\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139710293782144&#45;&gt;139710293778952 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139710293782144&#45;&gt;139710293778952</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M39.535,-56.6724C45.4798,-48.2176 52.5878,-38.1085 58.6352,-29.5078\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"61.5714,-31.4169 64.4601,-21.2234 55.8452,-27.3906 61.5714,-31.4169\"/>\n</g>\n<!-- 139710293781528 -->\n<g id=\"node3\" class=\"node\">\n<title>139710293781528</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"163.5,-85 72.5,-85 72.5,-64 163.5,-64 163.5,-85\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-71.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 139710293781528&#45;&gt;139710293778952 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139710293781528&#45;&gt;139710293778952</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M110.404,-63.9317C103.7191,-54.6309 93.821,-40.8597 85.7479,-29.6276\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"88.4395,-27.3753 79.761,-21.2979 82.7553,-31.4608 88.4395,-27.3753\"/>\n</g>\n<!-- 139710293779960 -->\n<g id=\"node4\" class=\"node\">\n<title>139710293779960</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"145,-163 91,-163 91,-128 145,-128 145,-163\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-135.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139710293779960&#45;&gt;139710293781528 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139710293779960&#45;&gt;139710293781528</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M118,-127.9494C118,-118.058 118,-105.6435 118,-95.2693\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"121.5001,-95.0288 118,-85.0288 114.5001,-95.0289 121.5001,-95.0288\"/>\n</g>\n</g>\n</svg>\n"},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":477},"id":"WM659o-Ue80X","executionInfo":{"status":"ok","timestamp":1611208234601,"user_tz":300,"elapsed":297,"user":{"displayName":"Ioannis Koutis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64","userId":"17239720917701380808"}},"outputId":"2ba14ded-27ac-41db-e5f9-4d9d6f40fef7"},"source":["make_dot(loss)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<graphviz.dot.Digraph at 0x7f10d66dbf98>"],"image/svg+xml":"<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"172pt\" height=\"342pt\"\n viewBox=\"0.00 0.00 171.50 342.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 338)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-338 167.5,-338 167.5,4 -4,4\"/>\n<!-- 139710293718856 -->\n<g id=\"node1\" class=\"node\">\n<title>139710293718856</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"121,-21 23,-21 23,0 121,0 121,-21\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MeanBackward0</text>\n</g>\n<!-- 139710293719416 -->\n<g id=\"node2\" class=\"node\">\n<title>139710293719416</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"118.5,-78 25.5,-78 25.5,-57 118.5,-57 118.5,-78\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">PowBackward0</text>\n</g>\n<!-- 139710293719416&#45;&gt;139710293718856 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139710293719416&#45;&gt;139710293718856</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M72,-56.7787C72,-49.6134 72,-39.9517 72,-31.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.5001,-31.1732 72,-21.1732 68.5001,-31.1732 75.5001,-31.1732\"/>\n</g>\n<!-- 139710293719304 -->\n<g id=\"node3\" class=\"node\">\n<title>139710293719304</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"117,-135 27,-135 27,-114 117,-114 117,-135\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SubBackward0</text>\n</g>\n<!-- 139710293719304&#45;&gt;139710293719416 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139710293719304&#45;&gt;139710293719416</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M72,-113.7787C72,-106.6134 72,-96.9517 72,-88.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.5001,-88.1732 72,-78.1732 68.5001,-88.1732 75.5001,-88.1732\"/>\n</g>\n<!-- 139710293719248 -->\n<g id=\"node4\" class=\"node\">\n<title>139710293719248</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"118,-192 26,-192 26,-171 118,-171 118,-192\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 139710293719248&#45;&gt;139710293719304 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139710293719248&#45;&gt;139710293719304</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M72,-170.7787C72,-163.6134 72,-153.9517 72,-145.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.5001,-145.1732 72,-135.1732 68.5001,-145.1732 75.5001,-145.1732\"/>\n</g>\n<!-- 139710293719976 -->\n<g id=\"node5\" class=\"node\">\n<title>139710293719976</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"54,-263 0,-263 0,-228 54,-228 54,-263\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-235.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139710293719976&#45;&gt;139710293719248 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139710293719976&#45;&gt;139710293719248</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M39.535,-227.6724C45.4798,-219.2176 52.5878,-209.1085 58.6352,-200.5078\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"61.5714,-202.4169 64.4601,-192.2234 55.8452,-198.3906 61.5714,-202.4169\"/>\n</g>\n<!-- 139710293720368 -->\n<g id=\"node6\" class=\"node\">\n<title>139710293720368</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"163.5,-256 72.5,-256 72.5,-235 163.5,-235 163.5,-256\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-242.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 139710293720368&#45;&gt;139710293719248 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139710293720368&#45;&gt;139710293719248</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M110.404,-234.9317C103.7191,-225.6309 93.821,-211.8597 85.7479,-200.6276\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"88.4395,-198.3753 79.761,-192.2979 82.7553,-202.4608 88.4395,-198.3753\"/>\n</g>\n<!-- 139710293717624 -->\n<g id=\"node7\" class=\"node\">\n<title>139710293717624</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"145,-334 91,-334 91,-299 145,-299 145,-334\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-306.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139710293717624&#45;&gt;139710293720368 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139710293717624&#45;&gt;139710293720368</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M118,-298.9494C118,-289.058 118,-276.6435 118,-266.2693\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"121.5001,-266.0288 118,-256.0288 114.5001,-266.0289 121.5001,-266.0288\"/>\n</g>\n</g>\n</svg>\n"},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":553},"id":"kq9v6TuIfmjZ","executionInfo":{"status":"ok","timestamp":1611208778242,"user_tz":300,"elapsed":299,"user":{"displayName":"Ioannis Koutis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64","userId":"17239720917701380808"}},"outputId":"a4a5cdbd-99a8-4d23-ae68-5d5c91ab15f3"},"source":["# DAGs can be as complicated as you want, with multiple branches\r\n","#\r\n","# the following code does not make sense, except that it is syntactically correct and generates a DAG\r\n","\r\n","yhat = a + b * x_train_tensor\r\n","error = y_train_tensor - yhat\r\n","loss = (error ** 2).mean()\r\n","\r\n","if loss>0:\r\n","  yhat2 = b * x_train_tensor\r\n","  error2 = y_train_tensor - yhat2\r\n","\r\n","loss += error2.mean()\r\n","\r\n","make_dot(loss)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<graphviz.dot.Digraph at 0x7f10ceba50b8>"],"image/svg+xml":"<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"284pt\" height=\"399pt\"\n viewBox=\"0.00 0.00 284.00 399.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 395)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-395 280,-395 280,4 -4,4\"/>\n<!-- 139710164521032 -->\n<g id=\"node1\" class=\"node\">\n<title>139710164521032</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"215,-21 123,-21 123,0 215,0 215,-21\"/>\n<text text-anchor=\"middle\" x=\"169\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 139710164521200 -->\n<g id=\"node2\" class=\"node\">\n<title>139710164521200</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"180,-78 82,-78 82,-57 180,-57 180,-78\"/>\n<text text-anchor=\"middle\" x=\"131\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MeanBackward0</text>\n</g>\n<!-- 139710164521200&#45;&gt;139710164521032 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139710164521200&#45;&gt;139710164521032</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M138.1475,-56.7787C143.2429,-49.1357 150.2317,-38.6524 156.2694,-29.596\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"159.2497,-31.4352 161.8845,-21.1732 153.4253,-27.5522 159.2497,-31.4352\"/>\n</g>\n<!-- 139710164521368 -->\n<g id=\"node3\" class=\"node\">\n<title>139710164521368</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"159.5,-135 66.5,-135 66.5,-114 159.5,-114 159.5,-135\"/>\n<text text-anchor=\"middle\" x=\"113\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">PowBackward0</text>\n</g>\n<!-- 139710164521368&#45;&gt;139710164521200 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139710164521368&#45;&gt;139710164521200</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M116.3857,-113.7787C118.6987,-106.4542 121.8354,-96.5211 124.61,-87.7352\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"127.9557,-88.763 127.6295,-78.1732 121.2806,-86.655 127.9557,-88.763\"/>\n</g>\n<!-- 139710164521480 -->\n<g id=\"node4\" class=\"node\">\n<title>139710164521480</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"158,-192 68,-192 68,-171 158,-171 158,-192\"/>\n<text text-anchor=\"middle\" x=\"113\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SubBackward0</text>\n</g>\n<!-- 139710164521480&#45;&gt;139710164521368 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139710164521480&#45;&gt;139710164521368</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M113,-170.7787C113,-163.6134 113,-153.9517 113,-145.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"116.5001,-145.1732 113,-135.1732 109.5001,-145.1732 116.5001,-145.1732\"/>\n</g>\n<!-- 139710164521592 -->\n<g id=\"node5\" class=\"node\">\n<title>139710164521592</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"159,-249 67,-249 67,-228 159,-228 159,-249\"/>\n<text text-anchor=\"middle\" x=\"113\" y=\"-235.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 139710164521592&#45;&gt;139710164521480 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139710164521592&#45;&gt;139710164521480</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M113,-227.7787C113,-220.6134 113,-210.9517 113,-202.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"116.5001,-202.1732 113,-192.1732 109.5001,-202.1732 116.5001,-202.1732\"/>\n</g>\n<!-- 139710164572872 -->\n<g id=\"node6\" class=\"node\">\n<title>139710164572872</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"54,-320 0,-320 0,-285 54,-285 54,-320\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-292.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139710164572872&#45;&gt;139710164521592 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139710164572872&#45;&gt;139710164521592</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.9558,-284.6724C63.3538,-275.446 78.3987,-264.2498 90.5683,-255.1934\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"92.9097,-257.8138 98.8425,-249.0358 88.7306,-252.1981 92.9097,-257.8138\"/>\n</g>\n<!-- 139710164521704 -->\n<g id=\"node7\" class=\"node\">\n<title>139710164521704</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"163.5,-313 72.5,-313 72.5,-292 163.5,-292 163.5,-313\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-299.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 139710164521704&#45;&gt;139710164521592 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139710164521704&#45;&gt;139710164521592</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M117.1744,-291.9317C116.4837,-283.0913 115.4775,-270.2122 114.6261,-259.3135\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"118.1119,-258.9949 113.8436,-249.2979 111.1332,-259.5402 118.1119,-258.9949\"/>\n</g>\n<!-- 139710164571080 -->\n<g id=\"node8\" class=\"node\">\n<title>139710164571080</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"199,-391 145,-391 145,-356 199,-356 199,-391\"/>\n<text text-anchor=\"middle\" x=\"172\" y=\"-363.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139710164571080&#45;&gt;139710164521704 -->\n<g id=\"edge7\" class=\"edge\">\n<title>139710164571080&#45;&gt;139710164521704</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M158.6517,-355.9494C150.6484,-345.4266 140.4734,-332.0484 132.3053,-321.3089\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"134.8474,-318.8695 126.0078,-313.0288 129.2757,-323.1071 134.8474,-318.8695\"/>\n</g>\n<!-- 139710164521648 -->\n<g id=\"node11\" class=\"node\">\n<title>139710164521648</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"272.5,-313 181.5,-313 181.5,-292 272.5,-292 272.5,-313\"/>\n<text text-anchor=\"middle\" x=\"227\" y=\"-299.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 139710164571080&#45;&gt;139710164521648 -->\n<g id=\"edge11\" class=\"edge\">\n<title>139710164571080&#45;&gt;139710164521648</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M185.5955,-355.9494C193.8285,-345.3214 204.3179,-331.7806 212.6787,-320.9875\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"215.4868,-323.0778 218.8439,-313.0288 209.9529,-318.7909 215.4868,-323.0778\"/>\n</g>\n<!-- 139710164521256 -->\n<g id=\"node9\" class=\"node\">\n<title>139710164521256</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"276,-135 178,-135 178,-114 276,-114 276,-135\"/>\n<text text-anchor=\"middle\" x=\"227\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MeanBackward0</text>\n</g>\n<!-- 139710164521256&#45;&gt;139710164521032 -->\n<g id=\"edge8\" class=\"edge\">\n<title>139710164521256&#45;&gt;139710164521032</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M221.6475,-113.9795C211.9855,-94.9888 191.4875,-54.6995 179.1119,-30.3751\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"182.1629,-28.6533 174.5088,-21.3276 175.9239,-31.8275 182.1629,-28.6533\"/>\n</g>\n<!-- 139710164521424 -->\n<g id=\"node10\" class=\"node\">\n<title>139710164521424</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"272,-249 182,-249 182,-228 272,-228 272,-249\"/>\n<text text-anchor=\"middle\" x=\"227\" y=\"-235.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SubBackward0</text>\n</g>\n<!-- 139710164521424&#45;&gt;139710164521256 -->\n<g id=\"edge9\" class=\"edge\">\n<title>139710164521424&#45;&gt;139710164521256</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M227,-227.9795C227,-209.242 227,-169.7701 227,-145.3565\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"230.5001,-145.3276 227,-135.3276 223.5001,-145.3277 230.5001,-145.3276\"/>\n</g>\n<!-- 139710164521648&#45;&gt;139710164521424 -->\n<g id=\"edge10\" class=\"edge\">\n<title>139710164521648&#45;&gt;139710164521424</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M227,-291.9317C227,-283.0913 227,-270.2122 227,-259.3135\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"230.5001,-259.2979 227,-249.2979 223.5001,-259.2979 230.5001,-259.2979\"/>\n</g>\n</g>\n</svg>\n"},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"QrKJCe-Ii5gE"},"source":["### **Actually, the optimizer can do the job for us**\r\n","\r\n","PyTorch implements various optimizers, and we can use any of them."]},{"cell_type":"code","metadata":{"id":"pZeEOPkLgs3o"},"source":["torch.manual_seed(42)\r\n","a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\r\n","b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\r\n","print(a, b)\r\n","\r\n","lr = 1e-1\r\n","n_epochs = 1000\r\n","\r\n","# Defines a SGD optimizer to update the parameters\r\n","optimizer = optim.SGD([a, b], lr=lr)\r\n","\r\n","for epoch in range(n_epochs):\r\n","    yhat = a + b * x_train_tensor\r\n","    error = y_train_tensor - yhat\r\n","    loss = (error ** 2).mean()\r\n","\r\n","    loss.backward()    \r\n","    \r\n","    # No more manual update!\r\n","    # with torch.no_grad():\r\n","    #     a -= lr * a.grad\r\n","    #     b -= lr * b.grad\r\n","    optimizer.step()\r\n","    \r\n","    # No more telling PyTorch to let gradients go!\r\n","    # a.grad.zero_()\r\n","    # b.grad.zero_()\r\n","    optimizer.zero_grad()\r\n","    \r\n","print(a, b)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ffrXkcxvmF78"},"source":["### **Wait, PyTorch can take care of the loss too**\r\n","\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1sB9J1LBmMMw","executionInfo":{"status":"ok","timestamp":1611210012138,"user_tz":300,"elapsed":553,"user":{"displayName":"Ioannis Koutis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64","userId":"17239720917701380808"}},"outputId":"e2048ad1-b250-4331-d5ba-893730e345d1"},"source":["\r\n","torch.manual_seed(42)\r\n","a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\r\n","b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\r\n","print(a, b)\r\n","\r\n","lr = 1e-1\r\n","n_epochs = 1000\r\n","\r\n","# Defines a MSE loss function\r\n","loss_fn = nn.MSELoss(reduction='mean')\r\n","\r\n","optimizer = optim.SGD([a, b], lr=lr)\r\n","\r\n","for epoch in range(n_epochs):\r\n","    yhat = a + b * x_train_tensor\r\n","    \r\n","    # No more manual loss!\r\n","    # error = y_tensor - yhat\r\n","    # loss = (error ** 2).mean()\r\n","    loss = loss_fn(y_train_tensor, yhat)   # Here the loss function only requires the true outputs and the predicted outputs\r\n","\r\n","    loss.backward()    \r\n","    optimizer.step()\r\n","    optimizer.zero_grad()\r\n","    \r\n","print(a, b)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n","tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SkCeyxyWopWr"},"source":["## **Pytorch: An entire model in a few lines (the most important part today)**\r\n","\r\n","In PyTorch the Module class can be 'subclassed' to create models that inherit some general characteristics. The most important part is that we need\r\n","to define the **parameters** of the model and a **forward** function, that defines how the model evaluates its inputs. \r\n"]},{"cell_type":"code","metadata":{"id":"TRg91TijmbN7"},"source":["# This is how to create a new class for creating Linear Regression models.\r\n","\r\n","class ManualLinearRegression(nn.Module):\r\n","    def __init__(self):\r\n","        super().__init__()\r\n","        # To make \"a\" and \"b\" real parameters of the model, we need to wrap them with nn.Parameter\r\n","        self.a = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\r\n","        self.b = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\r\n","        \r\n","    def forward(self, x):\r\n","        # Computes the outputs / predictions\r\n","        return self.a + self.b * x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oMmgiu32qP8F","executionInfo":{"status":"ok","timestamp":1611211022235,"user_tz":300,"elapsed":443,"user":{"displayName":"Ioannis Koutis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64","userId":"17239720917701380808"}},"outputId":"3201627d-b6d7-42e8-dac3-21a350862206"},"source":["\r\n","\r\n","torch.manual_seed(42)\r\n","\r\n","# Now we can create a model and send it at once to the device\r\n","model = ManualLinearRegression().to(device)\r\n","\r\n","# We can also inspect its parameters using its state_dict\r\n","print(model.state_dict())\r\n","\r\n","lr = 1e-1\r\n","n_epochs = 1000\r\n","\r\n","loss_fn = nn.MSELoss(reduction='mean')\r\n","optimizer = optim.SGD(model.parameters(), lr=lr)\r\n","\r\n","for epoch in range(n_epochs):\r\n","    \r\n","    # This sets the model in 'training' mode. We have to use this. \r\n","    model.train()\r\n","\r\n","    # No more manual prediction!\r\n","    # yhat = a + b * x_tensor\r\n","    yhat = model(x_train_tensor)\r\n","    \r\n","    loss = loss_fn(y_train_tensor, yhat)\r\n","    loss.backward()    \r\n","    optimizer.step()\r\n","    optimizer.zero_grad()\r\n","    \r\n","print(model.state_dict())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["OrderedDict([('a', tensor([0.3367])), ('b', tensor([0.1288]))])\n","OrderedDict([('a', tensor([1.0235])), ('b', tensor([1.9690]))])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WRD4prSprktl"},"source":["The simple linear model we created is very basic. PyTorch offers (under nn) multiple pre-made functions that can be used in the DAG. Here is how to do this here:"]},{"cell_type":"code","metadata":{"id":"-23kCnRJqQjL"},"source":["class LayerLinearRegression(nn.Module):\r\n","    def __init__(self):\r\n","        super().__init__()\r\n","        # Instead of our custom parameters, we use a Linear layer with single input and single output\r\n","        # this implicitly defines both a (the weight) and b (the intercept)\r\n","        self.linear = nn.Linear(1, 1)\r\n","                \r\n","    def forward(self, x):\r\n","        # Now it only takes a call to the layer to make predictions\r\n","        return self.linear(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oHshRp56sQ4r","executionInfo":{"status":"ok","timestamp":1611211545260,"user_tz":300,"elapsed":396,"user":{"displayName":"Ioannis Koutis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64","userId":"17239720917701380808"}},"outputId":"1ca3b1f7-850d-400c-df66-0443bdb92b95"},"source":["[*LayerLinearRegression().parameters()] "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Parameter containing:\n"," tensor([[-0.2191]], requires_grad=True), Parameter containing:\n"," tensor([0.2018], requires_grad=True)]"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"lBNQV7Xrsu7u"},"source":["### **Define a training function for better readability** "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sRpgK8m4suEd","executionInfo":{"status":"ok","timestamp":1611211733405,"user_tz":300,"elapsed":430,"user":{"displayName":"Ioannis Koutis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64","userId":"17239720917701380808"}},"outputId":"75dcbf70-12bb-47e9-91ef-d5986fd3bd32"},"source":["def make_train_step(model, loss_fn, optimizer):\r\n","    # Builds function that performs a step in the train loop\r\n","    def train_step(x, y):\r\n","        # Sets model to TRAIN mode\r\n","        model.train()\r\n","        # Makes predictions\r\n","        yhat = model(x)\r\n","        # Computes loss\r\n","        loss = loss_fn(y, yhat)\r\n","        # Computes gradients\r\n","        loss.backward()\r\n","        # Updates parameters and zeroes gradients\r\n","        optimizer.step()\r\n","        optimizer.zero_grad()\r\n","        # Returns the loss\r\n","        return loss.item()\r\n","    \r\n","    # Returns the function that will be called inside the train loop\r\n","    return train_step\r\n","\r\n","# Creates the train_step function for our model, loss function and optimizer\r\n","train_step = make_train_step(model, loss_fn, optimizer)\r\n","losses = []\r\n","\r\n","# For each epoch...\r\n","for epoch in range(n_epochs):\r\n","    # Performs one train step and returns the corresponding loss\r\n","    loss = train_step(x_train_tensor, y_train_tensor)\r\n","    losses.append(loss)\r\n","    \r\n","# Checks model's parameters\r\n","print(model.state_dict())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["OrderedDict([('a', tensor([1.0235])), ('b', tensor([1.9690]))])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ToxmgDk9sRji"},"source":[""],"execution_count":null,"outputs":[]}]}