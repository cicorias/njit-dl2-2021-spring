{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3892,
     "status": "ok",
     "timestamp": 1611277564068,
     "user": {
      "displayName": "Ioannis Koutis",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64",
      "userId": "17239720917701380808"
     },
     "user_tz": 300
    },
    "id": "TO_3Oef48HaY",
    "outputId": "7d18c0c4-0526-4394-b9ed-ec0254ad0291"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "import torch\r\n",
    "import time\r\n",
    "\r\n",
    "# All machines have CPUs but some machines have also GPUs\r\n",
    "# Having a GPU can make a huge difference\r\n",
    "\r\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1972,
     "status": "ok",
     "timestamp": 1611277804088,
     "user": {
      "displayName": "Ioannis Koutis",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64",
      "userId": "17239720917701380808"
     },
     "user_tz": 300
    },
    "id": "3A19YSp4Gb1r"
   },
   "outputs": [],
   "source": [
    "# Generate some random matrices. These are numpy, so they 'live' on the CPU\r\n",
    "\r\n",
    "n = 10000\r\n",
    "a = np.random.random([n,n])\r\n",
    "b = np.random.random([n,n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 11813,
     "status": "ok",
     "timestamp": 1611277816975,
     "user": {
      "displayName": "Ioannis Koutis",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64",
      "userId": "17239720917701380808"
     },
     "user_tz": 300
    },
    "id": "5Iu2HEE2GpE5"
   },
   "outputs": [],
   "source": [
    "# But we can put them on the GPU\r\n",
    "\r\n",
    "Ta  = torch.tensor(a).float().to(device)\r\n",
    "Tb  = torch.tensor(b).float().to(device)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24268,
     "status": "ok",
     "timestamp": 1611277859092,
     "user": {
      "displayName": "Ioannis Koutis",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhUpO_Yrmrro3LHDUXR4Z71Ig38y7Warh3Ph5dFgK0=s64",
      "userId": "17239720917701380808"
     },
     "user_tz": 300
    },
    "id": "0gEt2XjhIte6",
    "outputId": "40c08815-3239-4ba6-adcd-9456d4374c82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.409432649612427\n",
      "6.364349842071533\n"
     ]
    }
   ],
   "source": [
    "# Let's check the runtimes\r\n",
    "\r\n",
    "start = time.time()\r\n",
    "Tc = torch.matmul(Ta,Tb)\r\n",
    "end = time.time()\r\n",
    "print(end-start)\r\n",
    "\r\n",
    "# now let's put those back in the CPU and check again runtimes\r\n",
    "\r\n",
    "Ta = torch.Tensor.cpu(Ta)\r\n",
    "Tb = torch.Tensor.cpu(Tb)\r\n",
    "\r\n",
    "start = time.time()\r\n",
    "Tc = torch.matmul(Ta,Tb)\r\n",
    "end = time.time()\r\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X7OlrzWuJ_UJ"
   },
   "outputs": [],
   "source": [
    "# of course, most of the times we won't have to move data between CPU and GPU "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO7of8CpM7KrS1X9ZpVaM6w",
   "collapsed_sections": [],
   "name": "Using CUDA ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
